{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:28:26.889846Z","iopub.execute_input":"2025-07-02T20:28:26.890501Z","iopub.status.idle":"2025-07-02T20:28:26.895331Z","shell.execute_reply.started":"2025-07-02T20:28:26.890466Z","shell.execute_reply":"2025-07-02T20:28:26.894726Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Install just the 'evaluate' package; don’t upgrade or reinstall any of Kaggle’s other packages\n!pip install -q --no-deps evaluate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:28:26.901313Z","iopub.execute_input":"2025-07-02T20:28:26.901537Z","iopub.status.idle":"2025-07-02T20:28:28.338598Z","shell.execute_reply.started":"2025-07-02T20:28:26.901515Z","shell.execute_reply":"2025-07-02T20:28:28.337647Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# =============================================================================\n# CELL 2: Import Libraries and Setup\n# =============================================================================\n\nimport torch\nimport pandas as pd\nimport numpy as np\nimport sqlparse\nimport re\nfrom datasets import Dataset, load_dataset\nfrom transformers import (\n    AutoTokenizer, AutoModelForSeq2SeqLM, \n    TrainingArguments, Trainer, DataCollatorForSeq2Seq\n)\nfrom sklearn.model_selection import train_test_split\nfrom evaluate import load\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:28:28.340382Z","iopub.execute_input":"2025-07-02T20:28:28.340627Z","iopub.status.idle":"2025-07-02T20:28:28.345898Z","shell.execute_reply.started":"2025-07-02T20:28:28.340605Z","shell.execute_reply":"2025-07-02T20:28:28.345190Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# =============================================================================\n# CELL 3: Load and Filter Dataset\n# =============================================================================\n\n# Load the Gretel synthetic text-to-SQL dataset using your working method\nprint(\"Loading dataset...\")\n# Single \"train\" split on Hugging Face\nraw_ds = load_dataset(\"gretelai/synthetic_text_to_sql\", split=\"train\")\n\n# Convert to pandas for easy manipulation\ndf_raw = raw_ds.to_pandas()\nprint(\"Raw dataset shape:\", df_raw.shape)\nprint(\"Columns:\", df_raw.columns.tolist())\n\nprint(\"\\nMissing (NaN) values per column:\")\nprint(df_raw.isna().sum())\n\nprint(\"\\nEmpty-string values per column:\")\nprint((df_raw == \"\").sum())\n\nmask_raw = df_raw.isna().any(axis=1) | (df_raw == \"\").any(axis=1)\nprint(f\"\\nRows with ≥1 missing/empty field: {mask_raw.sum()}/{len(df_raw)}\")\n\n# Unique domains\nprint(\"\\nUnique domains:\", df_raw['domain'].unique())\n\n# For each domain, list the SQL task types (\"roles\")\ndomain_roles = df_raw.groupby('domain')['sql_task_type'].unique()\nprint(\"\\nSQL task types by domain:\")\nfor dom, roles in domain_roles.items():\n    print(f\"  {dom}: {roles}\")\n\n# Display sample row to understand structure\nprint(\"\\nSample row:\")\nprint(df_raw.iloc[0])\n\n# Filter for multiple domains: financial services, insurance, healthcare, and finance\ntarget_domains = ['financial services', 'insurance', 'healthcare', 'finance']\ndf_filtered = df_raw[df_raw['domain'].isin(target_domains)].copy()\n\nprint(f\"\\nFiltered dataset size (multiple domains): {len(df_filtered)}\")\n\n# Display distribution of selected domains\nprint(\"\\nSelected domains distribution:\")\nprint(df_filtered['domain'].value_counts())\n\n# Display distribution of all domains (for reference)\nprint(\"\\nAll domains distribution (top 10):\")\nprint(df_raw['domain'].value_counts().head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:28:28.346750Z","iopub.execute_input":"2025-07-02T20:28:28.347045Z","iopub.status.idle":"2025-07-02T20:28:29.801748Z","shell.execute_reply.started":"2025-07-02T20:28:28.347024Z","shell.execute_reply":"2025-07-02T20:28:29.800832Z"}},"outputs":[{"name":"stdout","text":"Loading dataset...\nRaw dataset shape: (100000, 11)\nColumns: ['id', 'domain', 'domain_description', 'sql_complexity', 'sql_complexity_description', 'sql_task_type', 'sql_task_type_description', 'sql_prompt', 'sql_context', 'sql', 'sql_explanation']\n\nMissing (NaN) values per column:\nid                            0\ndomain                        0\ndomain_description            0\nsql_complexity                0\nsql_complexity_description    0\nsql_task_type                 0\nsql_task_type_description     0\nsql_prompt                    0\nsql_context                   0\nsql                           0\nsql_explanation               0\ndtype: int64\n\nEmpty-string values per column:\nid                            0\ndomain                        0\ndomain_description            0\nsql_complexity                0\nsql_complexity_description    0\nsql_task_type                 0\nsql_task_type_description     0\nsql_prompt                    0\nsql_context                   0\nsql                           0\nsql_explanation               0\ndtype: int64\n\nRows with ≥1 missing/empty field: 0/100000\n\nUnique domains: ['forestry' 'defense industry' 'marine biology' 'financial services'\n 'energy' 'defense operations' 'aquaculture' 'nonprofit operations'\n 'public transportation' 'real estate' 'rural health'\n 'sustainable infrastructure' 'beauty industry' 'automotive'\n 'defense security' 'arts operations and management' 'biotechnology'\n 'cybersecurity' 'construction' 'agriculture' 'wildlife conservation'\n 'hospitality technology' 'venture capital' 'finance' 'space'\n 'telecommunications' 'maritime' 'healthcare' 'justice' 'tourism' 'media'\n 'public health' 'rural development' 'sports entertainment'\n 'public safety' 'retail' 'ethical fashion' 'restaurant operations'\n 'defense contractors' 'waste management' 'chemicals' 'philanthropy'\n 'gaming technology' 'oceanography' 'government policy' 'food industry'\n 'mining operations' 'civil engineering' 'manufacturing' 'startups'\n 'government services' 'entertainment industry' 'oil and gas'\n 'rare earth elements' 'transportation' 'fine arts' 'water resources'\n 'disability services' 'space exploration' 'oceans'\n 'charitable organizations' 'sustainable energy' 'nonprofit'\n 'ocean shipping' 'insurance' 'cosmetics' 'higher education'\n 'cannabis industry' 'arctic research' 'mental health' 'fitness industry'\n 'cultural preservation' 'legal services' 'technology' 'food services'\n 'aerospace' 'fashion' 'archeology' 'arts and culture' 'gaming industry'\n 'journalism' 'artificial intelligence' 'education' 'climate change'\n 'music industry' 'logistics' 'social media' 'human resources'\n 'pharmaceuticals' 'trade unions' 'museums' 'precision agriculture'\n 'hospitality' 'sports' 'mining industry' 'fashion retail'\n 'humanitarian aid' 'music' 'blockchain' 'social impact investing']\n\nSQL task types by domain:\n  aerospace: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  agriculture: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  aquaculture: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  archeology: ['analytics and reporting' 'data definition' 'data retrieval'\n 'data manipulation']\n  arctic research: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  artificial intelligence: ['analytics and reporting' 'data manipulation' 'data retrieval']\n  arts and culture: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  arts operations and management: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  automotive: ['data definition' 'analytics and reporting' 'data manipulation'\n 'data retrieval']\n  beauty industry: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  biotechnology: ['analytics and reporting' 'data retrieval' 'data manipulation'\n 'data definition']\n  blockchain: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  cannabis industry: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  charitable organizations: ['data manipulation' 'analytics and reporting' 'data retrieval']\n  chemicals: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  civil engineering: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  climate change: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  construction: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  cosmetics: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  cultural preservation: ['analytics and reporting' 'data definition' 'data manipulation'\n 'data retrieval']\n  cybersecurity: ['analytics and reporting' 'data manipulation' 'data retrieval']\n  defense contractors: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  defense industry: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  defense operations: ['analytics and reporting' 'data retrieval' 'data manipulation'\n 'data definition']\n  defense security: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  disability services: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  education: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  energy: ['analytics and reporting' 'data manipulation' 'data retrieval']\n  entertainment industry: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  ethical fashion: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  fashion: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  fashion retail: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  finance: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  financial services: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  fine arts: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  fitness industry: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  food industry: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  food services: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  forestry: ['analytics and reporting' 'data manipulation' 'data retrieval']\n  gaming industry: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  gaming technology: ['analytics and reporting' 'data definition' 'data manipulation'\n 'data retrieval']\n  government policy: ['data manipulation' 'analytics and reporting' 'data retrieval'\n 'data definition']\n  government services: ['data manipulation' 'analytics and reporting' 'data definition'\n 'data retrieval']\n  healthcare: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  higher education: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  hospitality: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  hospitality technology: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  human resources: ['analytics and reporting' 'data definition' 'data manipulation'\n 'data retrieval']\n  humanitarian aid: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  insurance: ['data definition' 'analytics and reporting' 'data manipulation'\n 'data retrieval']\n  journalism: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  justice: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  legal services: ['analytics and reporting' 'data definition' 'data retrieval'\n 'data manipulation']\n  logistics: ['analytics and reporting' 'data manipulation' 'data retrieval']\n  manufacturing: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  marine biology: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  maritime: ['analytics and reporting' 'data definition' 'data manipulation'\n 'data retrieval']\n  media: ['analytics and reporting' 'data retrieval' 'data manipulation']\n  mental health: ['analytics and reporting' 'data definition' 'data manipulation'\n 'data retrieval']\n  mining industry: ['analytics and reporting' 'data manipulation' 'data retrieval']\n  mining operations: ['analytics and reporting' 'data manipulation' 'data retrieval']\n  museums: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  music: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  music industry: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  nonprofit: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  nonprofit operations: ['data manipulation' 'analytics and reporting' 'data retrieval'\n 'data definition']\n  ocean shipping: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  oceanography: ['analytics and reporting' 'data manipulation' 'data retrieval']\n  oceans: ['analytics and reporting' 'data definition' 'data manipulation'\n 'data retrieval']\n  oil and gas: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  pharmaceuticals: ['analytics and reporting' 'data manipulation' 'data retrieval']\n  philanthropy: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  precision agriculture: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  public health: ['analytics and reporting' 'data definition' 'data manipulation']\n  public safety: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  public transportation: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  rare earth elements: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  real estate: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  restaurant operations: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  retail: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  rural development: ['analytics and reporting' 'data retrieval' 'data manipulation'\n 'data definition']\n  rural health: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  social impact investing: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  social media: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  space: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  space exploration: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  sports: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  sports entertainment: ['analytics and reporting' 'data definition' 'data manipulation'\n 'data retrieval']\n  startups: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  sustainable energy: ['analytics and reporting' 'data manipulation' 'data retrieval'\n 'data definition']\n  sustainable infrastructure: ['data manipulation' 'analytics and reporting' 'data definition'\n 'data retrieval']\n  technology: ['analytics and reporting' 'data definition' 'data manipulation'\n 'data retrieval']\n  telecommunications: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  tourism: ['analytics and reporting' 'data retrieval' 'data manipulation'\n 'data definition']\n  trade unions: ['analytics and reporting' 'data retrieval' 'data manipulation'\n 'data definition']\n  transportation: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  venture capital: ['analytics and reporting' 'data manipulation' 'data retrieval']\n  waste management: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n  water resources: ['analytics and reporting' 'data definition' 'data manipulation'\n 'data retrieval']\n  wildlife conservation: ['analytics and reporting' 'data manipulation' 'data definition'\n 'data retrieval']\n\nSample row:\nid                                                                         5097\ndomain                                                                 forestry\ndomain_description            Comprehensive data on sustainable forest manag...\nsql_complexity                                                      single join\nsql_complexity_description          only one join (specify inner, outer, cross)\nsql_task_type                                           analytics and reporting\nsql_task_type_description     generating reports, dashboards, and analytical...\nsql_prompt                    What is the total volume of timber sold by eac...\nsql_context                   CREATE TABLE salesperson (salesperson_id INT, ...\nsql                           SELECT salesperson_id, name, SUM(volume) as to...\nsql_explanation               Joins timber_sales and salesperson tables, gro...\nName: 0, dtype: object\n\nFiltered dataset size (multiple domains): 4318\n\nSelected domains distribution:\ndomain\nhealthcare            1193\nfinancial services    1134\nfinance               1051\ninsurance              940\nName: count, dtype: int64\n\nAll domains distribution (top 10):\ndomain\nethical fashion               1368\ncybersecurity                 1360\nrural development             1357\nhospitality                   1296\nsustainable infrastructure    1266\nwaste management              1240\ntelecommunications            1216\ngaming technology             1208\neducation                     1204\nhuman resources               1204\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# =============================================================================\n# CELL 4: Data Preprocessing and Format Preparation (BETTER PROMPTING)\n# =============================================================================\n\ndef prepare_input_output(row):\n    \"\"\"\n    Prepare input and output format for the models\n    Input: schema + natural language query (with better prompting)\n    Output: SQL + explanation\n    \"\"\"\n    # Create input text with better prompting\n    input_text = f\"\"\"Convert this natural language question to SQL using the given database schema.\n\nDatabase Schema:\n{row['sql_context']}\n\nQuestion: {row['sql_prompt']}\n\nPlease generate a SQL query with explanation:\"\"\"\n    \n    # Create output text (SQL + explanation) - unchanged\n    sql_query = row['sql']\n    explanation = row.get('sql_explanation', 'No explanation provided')\n    output_text = f\"SQL: {sql_query}\\nExplanation: {explanation}\"\n    \n    return input_text, output_text\n\n# Prepare the data\nprint(\"Preparing input-output pairs...\")\ninputs = []\noutputs = []\n\nfor idx, row in df_filtered.iterrows():\n    input_text, output_text = prepare_input_output(row)\n    inputs.append(input_text)\n    outputs.append(output_text)\n\n# Create DataFrame with processed data\nprocessed_df = pd.DataFrame({\n    'input': inputs,\n    'output': outputs\n})\n\nprint(f\"Processed {len(processed_df)} examples\")\nprint(\"\\nSample input:\")\nprint(processed_df['input'].iloc[0][:400] + \"...\")\nprint(\"\\nSample output:\")\nprint(processed_df['output'].iloc[0][:300] + \"...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:28:29.802613Z","iopub.execute_input":"2025-07-02T20:28:29.802843Z","iopub.status.idle":"2025-07-02T20:28:30.009802Z","shell.execute_reply.started":"2025-07-02T20:28:29.802827Z","shell.execute_reply":"2025-07-02T20:28:30.009105Z"}},"outputs":[{"name":"stdout","text":"Preparing input-output pairs...\nProcessed 4318 examples\n\nSample input:\nConvert this natural language question to SQL using the given database schema.\n\nDatabase Schema:\nCREATE TABLE trade_history (id INT, trader_id INT, stock VARCHAR(255), price DECIMAL(5,2), quantity INT, trade_time TIMESTAMP);\n\nQuestion: What is the total trade value and average price for each trader and stock in the trade_history table?\n\nPlease generate a SQL query with explanation:...\n\nSample output:\nSQL: SELECT trader_id, stock, SUM(price * quantity) as total_trade_value, AVG(price) as avg_price FROM trade_history GROUP BY trader_id, stock;\nExplanation: This query calculates the total trade value and average price for each trader and stock by grouping the trade_history table by the trader_id an...\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# =============================================================================\n# CELL 5: Train-Test Split\n# =============================================================================\n\n# Split the data\ntrain_df, test_df = train_test_split(processed_df, test_size=0.2, random_state=42)\ntrain_df, val_df = train_test_split(train_df, test_size=0.125, random_state=42)  # 0.125 * 0.8 = 0.1 of total\n\nprint(f\"Training set: {len(train_df)} examples\")\nprint(f\"Validation set: {len(val_df)} examples\") \nprint(f\"Test set: {len(test_df)} examples\")\n\n# Convert to HuggingFace datasets\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\ntest_dataset = Dataset.from_pandas(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:28:30.011665Z","iopub.execute_input":"2025-07-02T20:28:30.011869Z","iopub.status.idle":"2025-07-02T20:28:30.064694Z","shell.execute_reply.started":"2025-07-02T20:28:30.011853Z","shell.execute_reply":"2025-07-02T20:28:30.064185Z"}},"outputs":[{"name":"stdout","text":"Training set: 3022 examples\nValidation set: 432 examples\nTest set: 864 examples\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# =============================================================================\n# CELL 6: Model and Tokenizer Setup\n# =============================================================================\n\n# Model configurations\nmodels_config = {\n    'codet5-small': 'Salesforce/codet5-small',\n    # 't5-small': 't5-small'\n    'flan-t5-small': 'google/flan-t5-small' \n}\n\ndef setup_model_and_tokenizer(model_name):\n    \"\"\"Setup model and tokenizer\"\"\"\n    print(f\"Loading {model_name}...\")\n    \n    tokenizer = AutoTokenizer.from_pretrained(models_config[model_name])\n    model = AutoModelForSeq2SeqLM.from_pretrained(models_config[model_name])\n    \n    # Add special tokens if needed\n    if tokenizer.pad_token is None:\n        tokenizer.pad_token = tokenizer.eos_token\n    \n    model.to(device)\n    return model, tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:28:30.065288Z","iopub.execute_input":"2025-07-02T20:28:30.065479Z","iopub.status.idle":"2025-07-02T20:28:30.070336Z","shell.execute_reply.started":"2025-07-02T20:28:30.065464Z","shell.execute_reply":"2025-07-02T20:28:30.069443Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# =============================================================================\n# CELL 7: Data Tokenization Function\n# =============================================================================\n\ndef tokenize_data(examples, tokenizer, max_input_length=512, max_output_length=256):\n    \"\"\"Tokenize the input-output pairs\"\"\"\n    \n    # Tokenize inputs\n    model_inputs = tokenizer(\n        examples['input'],\n        max_length=max_input_length,\n        truncation=True,\n        padding=True,\n        return_tensors=\"pt\"\n    )\n    \n    # Tokenize outputs\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            examples['output'],\n            max_length=max_output_length,\n            truncation=True,\n            padding=True,\n            return_tensors=\"pt\"\n        )\n    \n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:28:30.071074Z","iopub.execute_input":"2025-07-02T20:28:30.071272Z","iopub.status.idle":"2025-07-02T20:28:30.079902Z","shell.execute_reply.started":"2025-07-02T20:28:30.071256Z","shell.execute_reply":"2025-07-02T20:28:30.079298Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# =============================================================================\n# CELL 8: Evaluation Functions\n# =============================================================================\n\ndef extract_sql_components(sql_text):\n    \"\"\"Extract structural components from SQL\"\"\"\n    try:\n        # Parse SQL\n        parsed = sqlparse.parse(sql_text)[0]\n        \n        components = {\n            'tables': set(),\n            'columns': set(),\n            'conditions': set(),\n            'functions': set()\n        }\n        \n        # Convert to string and extract components using regex\n        sql_str = str(parsed).upper()\n        \n        # Extract table names (simple heuristic)\n        from_match = re.search(r'FROM\\s+([^\\s\\(\\)]+)', sql_str)\n        if from_match:\n            components['tables'].add(from_match.group(1))\n        \n        join_matches = re.findall(r'JOIN\\s+([^\\s\\(\\)]+)', sql_str)\n        components['tables'].update(join_matches)\n        \n        # Extract common SQL functions\n        functions = re.findall(r'(COUNT|SUM|AVG|MIN|MAX|GROUP BY|ORDER BY)\\s*\\(', sql_str)\n        components['functions'].update(functions)\n        \n        # Extract WHERE conditions (simplified)\n        where_match = re.search(r'WHERE\\s+(.+?)(?:GROUP|ORDER|$)', sql_str)\n        if where_match:\n            conditions = where_match.group(1).strip()\n            components['conditions'].add(conditions)\n        \n        return components\n        \n    except Exception as e:\n        return {'tables': set(), 'columns': set(), 'conditions': set(), 'functions': set()}\n\n# def can_parse_sql(sql_text):\n#     \"\"\"Check if SQL can be parsed (syntax correctness)\"\"\"\n#     try:\n#         sqlparse.parse(sql_text)\n#         return 1.0\n#     except:\n#         return 0.0\n\ndef can_parse_sql(sql_text):\n    try:\n        parsed = sqlparse.parse(sql_text)[0]\n        # Check if it actually looks like a SQL statement\n        sql_upper = str(parsed).upper().strip()\n        \n        # Must start with SQL keywords\n        valid_starts = ('SELECT', 'INSERT', 'UPDATE', 'DELETE', 'CREATE', 'ALTER')\n        if not any(sql_upper.startswith(keyword) for keyword in valid_starts):\n            return 0.0\n            \n        # Must have basic SQL structure\n        if 'SELECT' in sql_upper and 'FROM' not in sql_upper:\n            return 0.0  # SELECT without FROM is usually invalid\n            \n        return 1.0\n    except:\n        return 0.0\n\ndef structural_similarity(ref_sql, gen_sql):\n    \"\"\"Calculate structural similarity between reference and generated SQL\"\"\"\n    ref_components = extract_sql_components(ref_sql)\n    gen_components = extract_sql_components(gen_sql)\n    \n    similarities = []\n    \n    for component_type in ['tables', 'functions', 'conditions']:\n        ref_set = ref_components[component_type]\n        gen_set = gen_components[component_type]\n        \n        if len(ref_set) == 0 and len(gen_set) == 0:\n            similarities.append(1.0)\n        elif len(ref_set) == 0 or len(gen_set) == 0:\n            similarities.append(0.0)\n        else:\n            # Jaccard similarity\n            intersection = len(ref_set & gen_set)\n            union = len(ref_set | gen_set)\n            similarities.append(intersection / union if union > 0 else 0.0)\n    \n    return np.mean(similarities)\n\ndef exact_match_score(ref_text, gen_text):\n    \"\"\"Calculate exact match after normalization\"\"\"\n    # Simple normalization\n    ref_normalized = re.sub(r'\\s+', ' ', ref_text.strip().lower())\n    gen_normalized = re.sub(r'\\s+', ' ', gen_text.strip().lower())\n    return 1.0 if ref_normalized == gen_normalized else 0.0\n\ndef split_sql_explanation(text):\n    \"\"\"Split combined SQL+explanation text\"\"\"\n    # Look for SQL: and Explanation: markers\n    sql_match = re.search(r'SQL:\\s*(.*?)(?=\\nExplanation:|$)', text, re.DOTALL)\n    exp_match = re.search(r'Explanation:\\s*(.*?)$', text, re.DOTALL)\n    \n    sql = sql_match.group(1).strip() if sql_match else text\n    explanation = exp_match.group(1).strip() if exp_match else \"\"\n    \n    return sql, explanation\n\ndef evaluate_predictions(references, predictions):\n    \"\"\"Comprehensive evaluation of predictions\"\"\"\n    \n    # Load BLEU metric\n    bleu_metric = load(\"bleu\")\n    \n    results = {\n        'syntax_scores': [],\n        'structural_scores': [],\n        'exact_match_scores': [],\n        'explanation_bleu_scores': [],\n        'combined_scores': []\n    }\n    \n    for ref, pred in zip(references, predictions):\n        # Split SQL and explanations\n        ref_sql, ref_exp = split_sql_explanation(ref)\n        pred_sql, pred_exp = split_sql_explanation(pred)\n        \n        # Calculate individual scores\n        syntax_score = can_parse_sql(pred_sql)\n        structural_score = structural_similarity(ref_sql, pred_sql)\n        exact_score = exact_match_score(ref_sql, pred_sql)\n        \n        # BLEU for explanations\n        if ref_exp and pred_exp:\n            bleu_score = bleu_metric.compute(\n                predictions=[pred_exp], \n                references=[[ref_exp]]\n            )['bleu']\n        else:\n            bleu_score = 0.0\n        \n        # Combined score\n        combined_score = (0.2 * syntax_score + \n                         0.4 * structural_score + \n                         0.1 * exact_score + \n                         0.3 * bleu_score)\n        \n        # Store results\n        results['syntax_scores'].append(syntax_score)\n        results['structural_scores'].append(structural_score)\n        results['exact_match_scores'].append(exact_score)\n        results['explanation_bleu_scores'].append(bleu_score)\n        results['combined_scores'].append(combined_score)\n    \n    # Calculate averages\n    avg_results = {key: np.mean(values) for key, values in results.items()}\n    \n    return avg_results, results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:28:30.080618Z","iopub.execute_input":"2025-07-02T20:28:30.080836Z","iopub.status.idle":"2025-07-02T20:28:30.097724Z","shell.execute_reply.started":"2025-07-02T20:28:30.080821Z","shell.execute_reply":"2025-07-02T20:28:30.097026Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# =============================================================================\n# CELL 9: Zero-Shot Evaluation Function\n# =============================================================================\n\ndef zero_shot_evaluation(model, tokenizer, test_dataset, model_name):\n    \"\"\"Perform zero-shot evaluation\"\"\"\n    print(f\"\\n=== Zero-Shot Evaluation for {model_name} ===\")\n    \n    model.eval()\n    predictions = []\n    references = []\n    \n    # Generate predictions\n    for i, example in enumerate(test_dataset):\n        if i % 20 == 0:\n            print(f\"Processing example {i+1}/{len(test_dataset)}\")\n        \n        input_text = example['input']\n        reference = example['output']\n        \n        # Tokenize input\n        inputs = tokenizer(\n            input_text, \n            return_tensors=\"pt\", \n            max_length=512, \n            truncation=True\n        ).to(device)\n        \n        # Generate prediction\n        with torch.no_grad():\n            outputs = model.generate(\n                **inputs,\n                max_length=256,\n                num_beams=2,\n                early_stopping=True\n            )\n        \n        # Decode prediction\n        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        \n        predictions.append(prediction)\n        references.append(reference)\n    \n    # Evaluate\n    avg_results, detailed_results = evaluate_predictions(references, predictions)\n    \n    print(f\"\\nZero-Shot Results for {model_name}:\")\n    print(f\"Syntax Correctness: {avg_results['syntax_scores']:.3f}\")\n    print(f\"Structural Similarity: {avg_results['structural_scores']:.3f}\")\n    print(f\"Exact Match: {avg_results['exact_match_scores']:.3f}\")\n    print(f\"Explanation BLEU: {avg_results['explanation_bleu_scores']:.3f}\")\n    print(f\"Combined Score: {avg_results['combined_scores']:.3f}\")\n    \n    return avg_results, predictions, references","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:28:30.098408Z","iopub.execute_input":"2025-07-02T20:28:30.098604Z","iopub.status.idle":"2025-07-02T20:28:30.112374Z","shell.execute_reply.started":"2025-07-02T20:28:30.098587Z","shell.execute_reply":"2025-07-02T20:28:30.111674Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# =============================================================================\n# CELL 10: Fine-tuning Function\n# =============================================================================\n\ndef fine_tune_model(model, tokenizer, train_dataset, val_dataset, model_name):\n    \"\"\"Fine-tune the model\"\"\"\n    print(f\"\\n=== Fine-tuning {model_name} ===\")\n\n      # Disable wandb\n    import os\n    os.environ[\"WANDB_DISABLED\"] = \"true\"\n    \n    # Tokenize datasets\n    def tokenize_function(examples):\n        return tokenize_data(examples, tokenizer)\n    \n    tokenized_train = train_dataset.map(tokenize_function, batched=True)\n    tokenized_val = val_dataset.map(tokenize_function, batched=True)\n    \n    # Data collator\n    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n    \n    # Training arguments\n    training_args = TrainingArguments(\n        output_dir=f'./results_{model_name}',\n        num_train_epochs=3,\n        per_device_train_batch_size=4,\n        per_device_eval_batch_size=4,\n        warmup_steps=50,\n        weight_decay=0.01,\n        logging_dir=f'./logs_{model_name}',\n        logging_steps=10,\n        eval_strategy=\"steps\",\n        eval_steps=50,\n        save_strategy=\"steps\",\n        save_steps=100,\n        load_best_model_at_end=True,\n        metric_for_best_model=\"eval_loss\",\n        greater_is_better=False,\n        save_total_limit=2,\n        gradient_accumulation_steps=2,\n        fp16=True if torch.cuda.is_available() else False,\n    )\n\n    # training_args = TrainingArguments(\n    #     # Output and logging\n    #     output_dir=f'./results_{model_name}',\n    #     logging_dir=f'./logs_{model_name}',\n    #     logging_steps=25,                      # Log less frequently\n        \n    #     # Training schedule\n    #     num_train_epochs=3,\n    #     per_device_train_batch_size=6,         # Increased from 4 (better GPU utilization)\n    #     per_device_eval_batch_size=8,          # Higher for evaluation (no gradients)\n    #     gradient_accumulation_steps=1,         # Reduced since batch size increased\n        \n    #     # Learning rate and scheduling  \n    #     learning_rate=3e-4,                    # Slightly higher for better convergence\n    #     lr_scheduler_type=\"cosine_with_restarts\", # Better than pure cosine\n    #     warmup_ratio=0.06,                     # 6% warmup (shorter for small dataset)\n        \n    #     # Regularization and stability\n    #     weight_decay=0.01,                     # Light regularization\n    #     max_grad_norm=1.0,                     # Gradient clipping\n        \n    #     # Evaluation and saving\n    #     eval_strategy=\"steps\",\n    #     eval_steps=100,                        # Less frequent evaluation\n    #     save_strategy=\"steps\", \n    #     save_steps=200,                        # Save less frequently\n    #     load_best_model_at_end=True,\n    #     metric_for_best_model=\"eval_loss\",\n    #     greater_is_better=False,\n    #     save_total_limit=1,                    # Keep only best model (save space)\n        \n    #     # Memory and performance optimization\n    #     fp16=True,                             # Half precision (faster + less memory)\n    #     dataloader_num_workers=2,              # Faster data loading\n    #     remove_unused_columns=False,           # Sometimes helps with seq2seq\n    #     prediction_loss_only=True,             # Focus on loss during evaluation\n        \n    #     # Kaggle-specific optimizations\n    #     dataloader_pin_memory=True,            # Faster GPU transfers\n    #     skip_memory_metrics=True,              # Reduce logging overhead\n    #     report_to=None,                        # Disable all experiment tracking\n    # )\n    \n    # Trainer\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_train,\n        eval_dataset=tokenized_val,\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n    )\n    \n    # Train\n    print(\"Starting training...\")\n    trainer.train()\n    \n    print(f\"Fine-tuning completed for {model_name}\")\n    return trainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:28:30.113051Z","iopub.execute_input":"2025-07-02T20:28:30.113323Z","iopub.status.idle":"2025-07-02T20:28:30.129908Z","shell.execute_reply.started":"2025-07-02T20:28:30.113301Z","shell.execute_reply":"2025-07-02T20:28:30.129248Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# =============================================================================\n# CELL 11: Post Fine-tuning Evaluation Function\n# =============================================================================\n\ndef post_finetune_evaluation(model, tokenizer, test_dataset, model_name):\n    \"\"\"Evaluate model after fine-tuning\"\"\"\n    print(f\"\\n=== Post Fine-tuning Evaluation for {model_name} ===\")\n    \n    return zero_shot_evaluation(model, tokenizer, test_dataset, f\"{model_name}_finetuned\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:28:30.130598Z","iopub.execute_input":"2025-07-02T20:28:30.130808Z","iopub.status.idle":"2025-07-02T20:28:30.143553Z","shell.execute_reply.started":"2025-07-02T20:28:30.130794Z","shell.execute_reply":"2025-07-02T20:28:30.142961Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# =============================================================================\n# CELL 11.5: Device Setup\n# =============================================================================\n\n# Set up device (GPU if available, otherwise CPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# If using GPU, print GPU info\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\nelse:\n    print(\"GPU not available, using CPU\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:28:30.144441Z","iopub.execute_input":"2025-07-02T20:28:30.144641Z","iopub.status.idle":"2025-07-02T20:28:30.156107Z","shell.execute_reply.started":"2025-07-02T20:28:30.144628Z","shell.execute_reply":"2025-07-02T20:28:30.155449Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nGPU: Tesla T4\nMemory: 14.7 GB\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# =============================================================================\n# CELL 12: Run Complete Experiment - CodeT5-Small\n# =============================================================================\n\nprint(\"=\"*60)\nprint(\"STARTING EXPERIMENT WITH CODET5-SMALL\")\nprint(\"=\"*60)\n\n# Setup CodeT5-Small\ncodet5_model, codet5_tokenizer = setup_model_and_tokenizer('codet5-small')\n\n# Zero-shot evaluation\ncodet5_zero_results, codet5_zero_preds, codet5_zero_refs = zero_shot_evaluation(\n    codet5_model, codet5_tokenizer, test_dataset, 'CodeT5-Small'\n)\n\n# Fine-tune CodeT5-Small\ncodet5_trainer = fine_tune_model(\n    codet5_model, codet5_tokenizer, train_dataset, val_dataset, 'codet5-small'\n)\n\n# Post fine-tuning evaluation\ncodet5_ft_results, codet5_ft_preds, codet5_ft_refs = post_finetune_evaluation(\n    codet5_model, codet5_tokenizer, test_dataset, 'CodeT5-Small'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:28:30.156769Z","iopub.execute_input":"2025-07-02T20:28:30.156967Z","iopub.status.idle":"2025-07-02T21:02:31.045012Z","shell.execute_reply.started":"2025-07-02T20:28:30.156948Z","shell.execute_reply":"2025-07-02T21:02:31.044346Z"}},"outputs":[{"name":"stdout","text":"============================================================\nSTARTING EXPERIMENT WITH CODET5-SMALL\n============================================================\nLoading codet5-small...\n\n=== Zero-Shot Evaluation for CodeT5-Small ===\nProcessing example 1/864\nProcessing example 21/864\nProcessing example 41/864\nProcessing example 61/864\nProcessing example 81/864\nProcessing example 101/864\nProcessing example 121/864\nProcessing example 141/864\nProcessing example 161/864\nProcessing example 181/864\nProcessing example 201/864\nProcessing example 221/864\nProcessing example 241/864\nProcessing example 261/864\nProcessing example 281/864\nProcessing example 301/864\nProcessing example 321/864\nProcessing example 341/864\nProcessing example 361/864\nProcessing example 381/864\nProcessing example 401/864\nProcessing example 421/864\nProcessing example 441/864\nProcessing example 461/864\nProcessing example 481/864\nProcessing example 501/864\nProcessing example 521/864\nProcessing example 541/864\nProcessing example 561/864\nProcessing example 581/864\nProcessing example 601/864\nProcessing example 621/864\nProcessing example 641/864\nProcessing example 661/864\nProcessing example 681/864\nProcessing example 701/864\nProcessing example 721/864\nProcessing example 741/864\nProcessing example 761/864\nProcessing example 781/864\nProcessing example 801/864\nProcessing example 821/864\nProcessing example 841/864\nProcessing example 861/864\n\nZero-Shot Results for CodeT5-Small:\nSyntax Correctness: 0.005\nStructural Similarity: 0.203\nExact Match: 0.000\nExplanation BLEU: 0.000\nCombined Score: 0.082\n\n=== Fine-tuning codet5-small ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3022 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a8316a2a6bc42608699f58a27d4dc3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/432 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d88255a267a64f6f9faae5847a28ba46"}},"metadata":{}},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='567' max='567' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [567/567 07:11, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.796800</td>\n      <td>0.640370</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.619800</td>\n      <td>0.453571</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.558200</td>\n      <td>0.400075</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.458300</td>\n      <td>0.374543</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.433400</td>\n      <td>0.349339</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.427800</td>\n      <td>0.337480</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.423000</td>\n      <td>0.328616</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.388000</td>\n      <td>0.320610</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.378300</td>\n      <td>0.317735</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.354700</td>\n      <td>0.313231</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.337900</td>\n      <td>0.311711</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"name":"stdout","text":"Fine-tuning completed for codet5-small\n\n=== Post Fine-tuning Evaluation for CodeT5-Small ===\n\n=== Zero-Shot Evaluation for CodeT5-Small_finetuned ===\nProcessing example 1/864\nProcessing example 21/864\nProcessing example 41/864\nProcessing example 61/864\nProcessing example 81/864\nProcessing example 101/864\nProcessing example 121/864\nProcessing example 141/864\nProcessing example 161/864\nProcessing example 181/864\nProcessing example 201/864\nProcessing example 221/864\nProcessing example 241/864\nProcessing example 261/864\nProcessing example 281/864\nProcessing example 301/864\nProcessing example 321/864\nProcessing example 341/864\nProcessing example 361/864\nProcessing example 381/864\nProcessing example 401/864\nProcessing example 421/864\nProcessing example 441/864\nProcessing example 461/864\nProcessing example 481/864\nProcessing example 501/864\nProcessing example 521/864\nProcessing example 541/864\nProcessing example 561/864\nProcessing example 581/864\nProcessing example 601/864\nProcessing example 621/864\nProcessing example 641/864\nProcessing example 661/864\nProcessing example 681/864\nProcessing example 701/864\nProcessing example 721/864\nProcessing example 741/864\nProcessing example 761/864\nProcessing example 781/864\nProcessing example 801/864\nProcessing example 821/864\nProcessing example 841/864\nProcessing example 861/864\n\nZero-Shot Results for CodeT5-Small_finetuned:\nSyntax Correctness: 0.993\nStructural Similarity: 0.638\nExact Match: 0.100\nExplanation BLEU: 0.286\nCombined Score: 0.549\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# =============================================================================\n# CELL 13: Run Complete Experiment - T5-Small\n# =============================================================================\n\nprint(\"=\"*60)\nprint(\"STARTING EXPERIMENT WITH T5-SMALL\")\nprint(\"=\"*60)\n\n# Setup T5-Small\n# t5_model, t5_tokenizer = setup_model_and_tokenizer('t5-small')\nt5_model, t5_tokenizer = setup_model_and_tokenizer('flan-t5-small')\n\n# Zero-shot evaluation\nt5_zero_results, t5_zero_preds, t5_zero_refs = zero_shot_evaluation(\n    t5_model, t5_tokenizer, test_dataset, 'T5-Small'\n)\n\n# Fine-tune T5-Small\nt5_trainer = fine_tune_model(\n    t5_model, t5_tokenizer, train_dataset, val_dataset, 't5-small'\n)\n\n# Post fine-tuning evaluation\nt5_ft_results, t5_ft_preds, t5_ft_refs = post_finetune_evaluation(\n    t5_model, t5_tokenizer, test_dataset, 'T5-Small'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T21:02:31.047629Z","iopub.execute_input":"2025-07-02T21:02:31.048051Z","iopub.status.idle":"2025-07-02T21:34:55.247615Z","shell.execute_reply.started":"2025-07-02T21:02:31.048032Z","shell.execute_reply":"2025-07-02T21:34:55.246808Z"}},"outputs":[{"name":"stdout","text":"============================================================\nSTARTING EXPERIMENT WITH T5-SMALL\n============================================================\nLoading flan-t5-small...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9a54f77e3814ba2bfc7269c421c2d6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77b907fdaf7b403ab679e3e71008f519"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"345cf9f4637a405ba37b7c78b926697f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdc5687fa04d4a22b49a259d99489922"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0f58971b37b4f7a8e0a4456da2847d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd7ffaf90fcf4f7a82c2347f4b295df6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4119b964b0d4cfa938f622dade2ac05"}},"metadata":{}},{"name":"stdout","text":"\n=== Zero-Shot Evaluation for T5-Small ===\nProcessing example 1/864\nProcessing example 21/864\nProcessing example 41/864\nProcessing example 61/864\nProcessing example 81/864\nProcessing example 101/864\nProcessing example 121/864\nProcessing example 141/864\nProcessing example 161/864\nProcessing example 181/864\nProcessing example 201/864\nProcessing example 221/864\nProcessing example 241/864\nProcessing example 261/864\nProcessing example 281/864\nProcessing example 301/864\nProcessing example 321/864\nProcessing example 341/864\nProcessing example 361/864\nProcessing example 381/864\nProcessing example 401/864\nProcessing example 421/864\nProcessing example 441/864\nProcessing example 461/864\nProcessing example 481/864\nProcessing example 501/864\nProcessing example 521/864\nProcessing example 541/864\nProcessing example 561/864\nProcessing example 581/864\nProcessing example 601/864\nProcessing example 621/864\nProcessing example 641/864\nProcessing example 661/864\nProcessing example 681/864\nProcessing example 701/864\nProcessing example 721/864\nProcessing example 741/864\nProcessing example 761/864\nProcessing example 781/864\nProcessing example 801/864\nProcessing example 821/864\nProcessing example 841/864\nProcessing example 861/864\n\nZero-Shot Results for T5-Small:\nSyntax Correctness: 0.049\nStructural Similarity: 0.203\nExact Match: 0.000\nExplanation BLEU: 0.000\nCombined Score: 0.091\n\n=== Fine-tuning t5-small ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3022 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6dc779d7f374473b296167ffdb81cc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/432 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"571a2675573f4befbfa42a20df3dd434"}},"metadata":{}},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='567' max='567' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [567/567 08:21, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>14.957900</td>\n      <td>10.292455</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>3.914600</td>\n      <td>3.371082</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>2.810800</td>\n      <td>2.332740</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>2.161900</td>\n      <td>1.644126</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.680100</td>\n      <td>1.173841</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.375200</td>\n      <td>0.907140</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.160500</td>\n      <td>0.769701</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.009600</td>\n      <td>0.692351</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.934600</td>\n      <td>0.647684</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.841600</td>\n      <td>0.623924</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.782100</td>\n      <td>0.612518</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n","output_type":"stream"},{"name":"stdout","text":"Fine-tuning completed for t5-small\n\n=== Post Fine-tuning Evaluation for T5-Small ===\n\n=== Zero-Shot Evaluation for T5-Small_finetuned ===\nProcessing example 1/864\nProcessing example 21/864\nProcessing example 41/864\nProcessing example 61/864\nProcessing example 81/864\nProcessing example 101/864\nProcessing example 121/864\nProcessing example 141/864\nProcessing example 161/864\nProcessing example 181/864\nProcessing example 201/864\nProcessing example 221/864\nProcessing example 241/864\nProcessing example 261/864\nProcessing example 281/864\nProcessing example 301/864\nProcessing example 321/864\nProcessing example 341/864\nProcessing example 361/864\nProcessing example 381/864\nProcessing example 401/864\nProcessing example 421/864\nProcessing example 441/864\nProcessing example 461/864\nProcessing example 481/864\nProcessing example 501/864\nProcessing example 521/864\nProcessing example 541/864\nProcessing example 561/864\nProcessing example 581/864\nProcessing example 601/864\nProcessing example 621/864\nProcessing example 641/864\nProcessing example 661/864\nProcessing example 681/864\nProcessing example 701/864\nProcessing example 721/864\nProcessing example 741/864\nProcessing example 761/864\nProcessing example 781/864\nProcessing example 801/864\nProcessing example 821/864\nProcessing example 841/864\nProcessing example 861/864\n\nZero-Shot Results for T5-Small_finetuned:\nSyntax Correctness: 0.889\nStructural Similarity: 0.349\nExact Match: 0.000\nExplanation BLEU: 0.208\nCombined Score: 0.380\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"# Debug: Check actual zero-shot predictions\nprint(\"=== DEBUGGING ZERO-SHOT OUTPUTS ===\")\nprint(f\"First CodeT5 prediction: {codet5_zero_preds[0]}\")\nprint(f\"First T5 prediction: {t5_zero_preds[0]}\")\nprint(f\"Are they identical? {codet5_zero_preds[0] == t5_zero_preds[0]}\")\n\nprint(f\"\\nSecond CodeT5 prediction: {codet5_zero_preds[1]}\")\nprint(f\"Second T5 prediction: {t5_zero_preds[1]}\")\nprint(f\"Are they identical? {codet5_zero_preds[1] == t5_zero_preds[1]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T21:34:55.248434Z","iopub.execute_input":"2025-07-02T21:34:55.248628Z","iopub.status.idle":"2025-07-02T21:34:55.253183Z","shell.execute_reply.started":"2025-07-02T21:34:55.248613Z","shell.execute_reply":"2025-07-02T21:34:55.252467Z"}},"outputs":[{"name":"stdout","text":"=== DEBUGGING ZERO-SHOT OUTPUTS ===\nFirst CodeT5 prediction: bank_namebank_namebank_namebank_name(bank_name)bank_namebank_name(bank_name)(bank_name)(bank_name)(bank_name)(bank_name)(bank_name)\nFirst T5 prediction: What is the total amount of socially responsible loans issued by each bank?\nAre they identical? False\n\nSecond CodeT5 prediction: () {\n\n\nQuestion:the amount ofthe amount ofthe amount ofthe customer_id, amount, tx_date, countrythe amount ofthe customer_id, amount, tx_date, countrythe amount ofthe customer_id, amount, tx_date, country,the customer_id, amount, tx_date, country,the amount ofthe customer_id, amount, tx_\nSecond T5 prediction: Count the transaction dates and the total transaction amount for transactions made by customers in India.\nAre they identical? False\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"# Debug: Check actual fine-tuned predictions\nprint(\"=== DEBUGGING FINE-TUNED OUTPUTS ===\")\nprint(f\"First CodeT5 fine-tuned prediction: {codet5_ft_preds[0]}\")\nprint(f\"First T5 fine-tuned prediction: {t5_ft_preds[0]}\")\nprint(f\"Are they identical? {codet5_ft_preds[0] == t5_ft_preds[0]}\")\n\nprint(f\"\\nSecond CodeT5 fine-tuned prediction: {codet5_ft_preds[1]}\")\nprint(f\"Second T5 fine-tuned prediction: {t5_ft_preds[1]}\")\nprint(f\"Are they identical? {codet5_ft_preds[1] == t5_ft_preds[1]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T21:34:55.253903Z","iopub.execute_input":"2025-07-02T21:34:55.254166Z","iopub.status.idle":"2025-07-02T21:34:55.268672Z","shell.execute_reply.started":"2025-07-02T21:34:55.254151Z","shell.execute_reply":"2025-07-02T21:34:55.267977Z"}},"outputs":[{"name":"stdout","text":"=== DEBUGGING FINE-TUNED OUTPUTS ===\nFirst CodeT5 fine-tuned prediction: SQL: SELECT bank_name, SUM(loan_amount) FROM socially_responsible_loans WHERE loan_date BETWEEN DATEADD(month, -1, GETDATE());\nExplanation: This query calculates the total amount of socially responsible loans issued by each bank by summing up the loan_amount column and filtering the results by bank_name and the loan_date column.\nFirst T5 fine-tuned prediction: SQL: SELECT bank_name, loan_amount FROM socially_responsible_loans WHERE bank_name = 'socially_responsible_loans'; Explanation: This query calculates the total amount of socially responsible loans issued by each bank.\nAre they identical? False\n\nSecond CodeT5 fine-tuned prediction: SQL: SELECT customer_id, tx_date, SUM(amount) FROM transactions_4 WHERE country = 'India';\nExplanation: This query finds the transaction dates and the total transaction amount for transactions made by customers residing in India. It does this by using the SUM function on the amount column, and filtering for rows where the country is 'India'.\nSecond T5 fine-tuned prediction: SQL: SELECT transaction_date, total_transaction_amount FROM transactions_4 WHERE country = 'India'; Explanation: This query calculates the total transaction amount for transactions made by customers residing in India.\nAre they identical? False\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# =============================================================================\n# CELL 14: Final Results Comparison\n# =============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"FINAL RESULTS COMPARISON\")\nprint(\"=\"*80)\n\n# Create comparison table\nresults_df = pd.DataFrame({\n    'Model': ['CodeT5-Small (Zero-shot)', 'CodeT5-Small (Fine-tuned)', \n              'T5-Small (Zero-shot)', 'T5-Small (Fine-tuned)'],\n    'Syntax Correctness': [\n        codet5_zero_results['syntax_scores'],\n        codet5_ft_results['syntax_scores'],\n        t5_zero_results['syntax_scores'],\n        t5_ft_results['syntax_scores']\n    ],\n    'Structural Similarity': [\n        codet5_zero_results['structural_scores'],\n        codet5_ft_results['structural_scores'],\n        t5_zero_results['structural_scores'],\n        t5_ft_results['structural_scores']\n    ],\n    'Exact Match': [\n        codet5_zero_results['exact_match_scores'],\n        codet5_ft_results['exact_match_scores'],\n        t5_zero_results['exact_match_scores'],\n        t5_ft_results['exact_match_scores']\n    ],\n    'Explanation BLEU': [\n        codet5_zero_results['explanation_bleu_scores'],\n        codet5_ft_results['explanation_bleu_scores'],\n        t5_zero_results['explanation_bleu_scores'],\n        t5_ft_results['explanation_bleu_scores']\n    ],\n    'Combined Score': [\n        codet5_zero_results['combined_scores'],\n        codet5_ft_results['combined_scores'],\n        t5_zero_results['combined_scores'],\n        t5_ft_results['combined_scores']\n    ]\n})\n\nprint(results_df.round(3))\n\n# Calculate improvements\nprint(\"\\n\" + \"=\"*50)\nprint(\"IMPROVEMENT ANALYSIS\")\nprint(\"=\"*50)\n\ncodet5_improvement = codet5_ft_results['combined_scores'] - codet5_zero_results['combined_scores']\nt5_improvement = t5_ft_results['combined_scores'] - t5_zero_results['combined_scores']\n\nprint(f\"CodeT5-Small improvement: {codet5_improvement:.3f}\")\nprint(f\"T5-Small improvement: {t5_improvement:.3f}\")\n\nprint(f\"\\nBest performing model: \", end=\"\")\nbest_score = max(codet5_ft_results['combined_scores'], t5_ft_results['combined_scores'])\nif codet5_ft_results['combined_scores'] == best_score:\n    print(\"CodeT5-Small (Fine-tuned)\")\nelse:\n    print(\"T5-Small (Fine-tuned)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T21:34:55.269333Z","iopub.execute_input":"2025-07-02T21:34:55.269525Z","iopub.status.idle":"2025-07-02T21:34:55.289543Z","shell.execute_reply.started":"2025-07-02T21:34:55.269506Z","shell.execute_reply":"2025-07-02T21:34:55.288972Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nFINAL RESULTS COMPARISON\n================================================================================\n                       Model  Syntax Correctness  Structural Similarity  \\\n0   CodeT5-Small (Zero-shot)               0.005                  0.203   \n1  CodeT5-Small (Fine-tuned)               0.993                  0.638   \n2       T5-Small (Zero-shot)               0.049                  0.203   \n3      T5-Small (Fine-tuned)               0.889                  0.349   \n\n   Exact Match  Explanation BLEU  Combined Score  \n0          0.0             0.000           0.082  \n1          0.1             0.286           0.549  \n2          0.0             0.000           0.091  \n3          0.0             0.208           0.380  \n\n==================================================\nIMPROVEMENT ANALYSIS\n==================================================\nCodeT5-Small improvement: 0.467\nT5-Small improvement: 0.289\n\nBest performing model: CodeT5-Small (Fine-tuned)\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"# =============================================================================\n# CELL 15: Sample Predictions Analysis\n# =============================================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SAMPLE PREDICTIONS ANALYSIS\")\nprint(\"=\"*60)\n\n# Show a few sample predictions\nfor i in range(min(3, len(test_dataset))):\n    print(f\"\\n--- Example {i+1} ---\")\n    print(f\"Input: {test_dataset[i]['input'][:200]}...\")\n    print(f\"\\nReference: {test_dataset[i]['output'][:200]}...\")\n    print(f\"\\nCodeT5 Zero-shot: {codet5_zero_preds[i][:200]}...\")\n    print(f\"\\nCodeT5 Fine-tuned: {codet5_ft_preds[i][:200]}...\")\n    print(f\"\\nT5 Zero-shot: {t5_zero_preds[i][:200]}...\")\n    print(f\"\\nT5 Fine-tuned: {t5_ft_preds[i][:200]}...\")\n    print(\"-\" * 60)\n\nprint(\"\\n🎉 EXPERIMENT COMPLETED SUCCESSFULLY! 🎉\")\nprint(\"Check the results above to analyze model performance.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T21:34:55.290306Z","iopub.execute_input":"2025-07-02T21:34:55.290533Z","iopub.status.idle":"2025-07-02T21:34:55.301166Z","shell.execute_reply.started":"2025-07-02T21:34:55.290518Z","shell.execute_reply":"2025-07-02T21:34:55.300353Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nSAMPLE PREDICTIONS ANALYSIS\n============================================================\n\n--- Example 1 ---\nInput: Convert this natural language question to SQL using the given database schema.\n\nDatabase Schema:\nCREATE TABLE socially_responsible_loans (bank_name VARCHAR(255), loan_amount DECIMAL(10,2), loan_date D...\n\nReference: SQL: SELECT bank_name, SUM(loan_amount) FROM socially_responsible_loans GROUP BY bank_name;\nExplanation: This query calculates the total amount of socially responsible loans issued by each bank by sum...\n\nCodeT5 Zero-shot: bank_namebank_namebank_namebank_name(bank_name)bank_namebank_name(bank_name)(bank_name)(bank_name)(bank_name)(bank_name)(bank_name)...\n\nCodeT5 Fine-tuned: SQL: SELECT bank_name, SUM(loan_amount) FROM socially_responsible_loans WHERE loan_date BETWEEN DATEADD(month, -1, GETDATE());\nExplanation: This query calculates the total amount of socially responsib...\n\nT5 Zero-shot: What is the total amount of socially responsible loans issued by each bank?...\n\nT5 Fine-tuned: SQL: SELECT bank_name, loan_amount FROM socially_responsible_loans WHERE bank_name = 'socially_responsible_loans'; Explanation: This query calculates the total amount of socially responsible loans iss...\n------------------------------------------------------------\n\n--- Example 2 ---\nInput: Convert this natural language question to SQL using the given database schema.\n\nDatabase Schema:\nCREATE TABLE transactions_4 (id INT, customer_id INT, amount DECIMAL(10,2), tx_date DATE, country VARCH...\n\nReference: SQL: SELECT tx_date, SUM(amount) as total_transaction_amount FROM transactions_4 WHERE country = 'India' GROUP BY tx_date;\nExplanation: The SQL query filters the transactions_4 table for transactions ...\n\nCodeT5 Zero-shot: () {\n\n\nQuestion:the amount ofthe amount ofthe amount ofthe customer_id, amount, tx_date, countrythe amount ofthe customer_id, amount, tx_date, countrythe amount ofthe customer_id, amount, tx_date, cou...\n\nCodeT5 Fine-tuned: SQL: SELECT customer_id, tx_date, SUM(amount) FROM transactions_4 WHERE country = 'India';\nExplanation: This query finds the transaction dates and the total transaction amount for transactions made by...\n\nT5 Zero-shot: Count the transaction dates and the total transaction amount for transactions made by customers in India....\n\nT5 Fine-tuned: SQL: SELECT transaction_date, total_transaction_amount FROM transactions_4 WHERE country = 'India'; Explanation: This query calculates the total transaction amount for transactions made by customers r...\n------------------------------------------------------------\n\n--- Example 3 ---\nInput: Convert this natural language question to SQL using the given database schema.\n\nDatabase Schema:\nCREATE TABLE Policyholders (PolicyholderID INT, Name VARCHAR(50)); CREATE TABLE Claims (PolicyholderID ...\n\nReference: SQL: SELECT Policyholders.PolicyholderID, Policyholders.Name FROM Policyholders LEFT JOIN Claims ON Policyholders.PolicyholderID = Claims.PolicyholderID WHERE Claims.PolicyholderID IS NULL;\nExplanatio...\n\nCodeT5 Zero-shot: .\n\nQuestion:(1,(2,)(3,)(3,)(3,)(3,)(3,)(3,(3,)(3,)(3,)(3,)(3,(3,)...\n\nCodeT5 Fine-tuned: SQL: SELECT Policyholders.Name, Policyholders.ClaimAmount FROM Policyholders INNER JOIN Claims ON Policyholders.PolicyholderID = Claims.PolicyholderID WHERE Claims.ClaimAmount < 2000;\nExplanation: Thi...\n\nT5 Zero-shot: List of policyholders who never made a claim....\n\nT5 Fine-tuned: SQL: SELECT COUNT(DISTINCT Claims) FROM Policyholders WHERE ClaimAmount = 'John Doe'; Explanation: This query lists the policyholders who have never made a claim....\n------------------------------------------------------------\n\n🎉 EXPERIMENT COMPLETED SUCCESSFULLY! 🎉\nCheck the results above to analyze model performance.\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"# # =============================================================================\n# # MANUAL TESTING: New Task for Fine-Tuned Models\n# # =============================================================================\n\n# # Define your custom test case\n# custom_schema = \"\"\"\n# CREATE TABLE employees (emp_id INT, name VARCHAR(100), department VARCHAR(50), salary DECIMAL(10,2), hire_date DATE);\n# CREATE TABLE projects (project_id INT, project_name VARCHAR(100), budget DECIMAL(12,2), start_date DATE);\n# CREATE TABLE assignments (emp_id INT, project_id INT, hours_worked DECIMAL(5,2));\n# \"\"\"\n\n# custom_question = \"Find all employees in the Engineering department who have worked more than 100 hours total across all projects, and show their names and total hours worked.\"\n\n# # Format the input (same as training format)\n# custom_input = f\"Schema: {custom_schema}\\nQuestion: {custom_question}\"\n\n# print(\"=== CUSTOM TEST CASE ===\")\n# print(\"Input:\")\n# print(custom_input)\n# print(\"\\n\" + \"=\"*60)\n\n# # Test both fine-tuned models\n# def test_custom_query(model, tokenizer, input_text, model_name):\n#     inputs = tokenizer(\n#         input_text,\n#         return_tensors=\"pt\",\n#         max_length=512,\n#         truncation=True\n#     ).to(device)\n    \n#     with torch.no_grad():\n#         outputs = model.generate(\n#             **inputs,\n#             max_length=256,\n#             num_beams=2,\n#             early_stopping=True\n#         )\n    \n#     prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n#     print(f\"\\n{model_name} Prediction:\")\n#     print(prediction)\n#     return prediction\n\n# # Test both models\n# codet5_custom = test_custom_query(codet5_model, codet5_tokenizer, custom_input, \"CodeT5-Small Fine-tuned\")\n# t5_custom = test_custom_query(t5_model, t5_tokenizer, custom_input, \"T5-Small Fine-tuned\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T21:34:55.301890Z","iopub.execute_input":"2025-07-02T21:34:55.302123Z","iopub.status.idle":"2025-07-02T21:34:55.315377Z","shell.execute_reply.started":"2025-07-02T21:34:55.302109Z","shell.execute_reply":"2025-07-02T21:34:55.314739Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"# =============================================================================\n# MANUAL TESTING: Easier Task for Fine-Tuned Models\n# =============================================================================\n\n# Define easier test cases (progressive difficulty)\nprint(\"=== EASIER CUSTOM TEST CASES ===\")\n\n# Test Case 1: Single table, simple filter\ncustom_schema_1 = \"\"\"\nCREATE TABLE employees (emp_id INT, name VARCHAR(100), department VARCHAR(50), salary DECIMAL(10,2));\n\"\"\"\n\ncustom_question_1 = \"Find all employees in the Engineering department and show their names and salaries.\"\n\n# Test Case 2: Single table with aggregation\ncustom_schema_2 = \"\"\"\nCREATE TABLE sales (sale_id INT, product VARCHAR(100), amount DECIMAL(10,2), region VARCHAR(50));\n\"\"\"\n\ncustom_question_2 = \"What is the total sales amount for each region?\"\n\n# Test Case 3: Simple join (2 tables)\ncustom_schema_3 = \"\"\"\nCREATE TABLE customers (customer_id INT, name VARCHAR(100), city VARCHAR(50));\nCREATE TABLE orders (order_id INT, customer_id INT, amount DECIMAL(10,2));\n\"\"\"\n\ncustom_question_3 = \"Show customer names and their order amounts.\"\n\n# Test all cases\ntest_cases = [\n    (custom_schema_1, custom_question_1, \"Single Table Filter\"),\n    (custom_schema_2, custom_question_2, \"Single Table Aggregation\"), \n    (custom_schema_3, custom_question_3, \"Simple Two-Table Join\")\n]\n\ndef test_custom_query(model, tokenizer, input_text, model_name):\n    inputs = tokenizer(\n        input_text,\n        return_tensors=\"pt\",\n        max_length=512,\n        truncation=True\n    ).to(device)\n    \n    with torch.no_grad():\n        outputs = model.generate(\n            **inputs,\n            max_length=256,\n            num_beams=2,\n            early_stopping=True\n        )\n    \n    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return prediction\n\n# Test all cases with both models\nfor i, (schema, question, test_name) in enumerate(test_cases, 1):\n    # Format input using better prompting\n    custom_input = f\"\"\"Convert this natural language question to SQL using the given database schema.\n\nDatabase Schema:\n{schema}\n\nQuestion: {question}\n\nPlease generate a SQL query with explanation:\"\"\"\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"TEST CASE {i}: {test_name}\")\n    print(f\"{'='*60}\")\n    print(\"Question:\", question)\n    print(\"Schema:\", schema.strip())\n    \n    # Test CodeT5\n    codet5_result = test_custom_query(codet5_model, codet5_tokenizer, custom_input, \"CodeT5\")\n    print(f\"\\n🤖 CodeT5 Result:\")\n    print(codet5_result)\n    \n    # Test FLAN-T5  \n    flan_t5_result = test_custom_query(t5_model, t5_tokenizer, custom_input, \"FLAN-T5\")\n    print(f\"\\n🤖 FLAN-T5 Result:\")\n    print(flan_t5_result)\n    \n    print(f\"\\n{'='*60}\")\n\nprint(\"\\n🎯 ANALYSIS:\")\nprint(\"Expected SQL queries:\")\nprint(\"1. SELECT name, salary FROM employees WHERE department = 'Engineering';\")  \nprint(\"2. SELECT region, SUM(amount) FROM sales GROUP BY region;\")\nprint(\"3. SELECT c.name, o.amount FROM customers c JOIN orders o ON c.customer_id = o.customer_id;\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T21:34:55.316114Z","iopub.execute_input":"2025-07-02T21:34:55.316383Z","iopub.status.idle":"2025-07-02T21:34:59.753775Z","shell.execute_reply.started":"2025-07-02T21:34:55.316355Z","shell.execute_reply":"2025-07-02T21:34:59.753157Z"}},"outputs":[{"name":"stdout","text":"=== EASIER CUSTOM TEST CASES ===\n\n============================================================\nTEST CASE 1: Single Table Filter\n============================================================\nQuestion: Find all employees in the Engineering department and show their names and salaries.\nSchema: CREATE TABLE employees (emp_id INT, name VARCHAR(100), department VARCHAR(50), salary DECIMAL(10,2));\n\n🤖 CodeT5 Result:\nSQL: SELECT employees.emp_id, employees.name, employees.salary FROM employees WHERE employees.department = 'Engineering';\nExplanation: This query finds all employees in the Engineering department and show their names and salaries.\n\n🤖 FLAN-T5 Result:\nSQL: SELECT em_id FROM employees WHERE department = 'Engineering'; Explanation: This query finds all employees in the Engineering department and shows their names and salaries.\n\n============================================================\n\n============================================================\nTEST CASE 2: Single Table Aggregation\n============================================================\nQuestion: What is the total sales amount for each region?\nSchema: CREATE TABLE sales (sale_id INT, product VARCHAR(100), amount DECIMAL(10,2), region VARCHAR(50));\n\n🤖 CodeT5 Result:\nSQL: SELECT region, SUM(amount) FROM sales WHERE region = 'US' GROUP BY region;\nExplanation: This query calculates the total sales amount for each region. It uses the SUM function to sum the amount for each region.\n\n🤖 FLAN-T5 Result:\nSQL: SELECT sales_id FROM sales WHERE product = 'sale_id' AND region = 'region'; Explanation: This query calculates the total sales amount for each region by using the sales_id function.\n\n============================================================\n\n============================================================\nTEST CASE 3: Simple Two-Table Join\n============================================================\nQuestion: Show customer names and their order amounts.\nSchema: CREATE TABLE customers (customer_id INT, name VARCHAR(100), city VARCHAR(50));\nCREATE TABLE orders (order_id INT, customer_id INT, amount DECIMAL(10,2));\n\n🤖 CodeT5 Result:\nSQL: SELECT name, city, ORDER BY amount DESC LIMIT 1;\nExplanation: The SQL query selects the name, city, and orders tables on the customer_id column.\n\n🤖 FLAN-T5 Result:\nSQL: SELECT customer_id, city, order, amount FROM customers WHERE customer_id = 'customer_id'; Explanation: This SQL query shows the customer_id, customer_id, order, amount, amount, and amount for customers.\n\n============================================================\n\n🎯 ANALYSIS:\nExpected SQL queries:\n1. SELECT name, salary FROM employees WHERE department = 'Engineering';\n2. SELECT region, SUM(amount) FROM sales GROUP BY region;\n3. SELECT c.name, o.amount FROM customers c JOIN orders o ON c.customer_id = o.customer_id;\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"# Quick install and import\n!pip install gradio\nimport gradio as gr\nprint(\"✅ Gradio installed successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T21:38:16.780396Z","iopub.execute_input":"2025-07-02T21:38:16.780652Z","iopub.status.idle":"2025-07-02T21:38:28.754485Z","shell.execute_reply.started":"2025-07-02T21:38:16.780633Z","shell.execute_reply":"2025-07-02T21:38:28.753580Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting gradio\n  Downloading gradio-5.35.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\nCollecting fastapi<1.0,>=0.115.2 (from gradio)\n  Downloading fastapi-0.115.14-py3-none-any.whl.metadata (27 kB)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.6.0-py3-none-any.whl.metadata (2.9 kB)\nCollecting gradio-client==1.10.4 (from gradio)\n  Downloading gradio_client-1.10.4-py3-none-any.whl.metadata (7.1 kB)\nCollecting groovy~=0.1 (from gradio)\n  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.1)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\nRequirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.3)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\nRequirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\nCollecting python-multipart>=0.0.18 (from gradio)\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\nCollecting ruff>=0.9.3 (from gradio)\n  Downloading ruff-0.12.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.47.1-py3-none-any.whl.metadata (6.2 kB)\nCollecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n  Downloading tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\nRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\nCollecting uvicorn>=0.14.0 (from gradio)\n  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.4->gradio) (2025.3.2)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.4->gradio) (15.0.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.0->gradio) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading gradio-5.35.0-py3-none-any.whl (54.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.10.4-py3-none-any.whl (323 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.14-py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.5/95.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\nDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading ruff-0.12.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\nDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\nDownloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ffmpy-0.6.0-py3-none-any.whl (5.5 kB)\nInstalling collected packages: uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, starlette, safehttpx, gradio-client, fastapi, gradio\nSuccessfully installed fastapi-0.115.14 ffmpy-0.6.0 gradio-5.35.0 gradio-client-1.10.4 groovy-0.1.2 python-multipart-0.0.20 ruff-0.12.1 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.3 uvicorn-0.35.0\n✅ Gradio installed successfully!\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"# =============================================================================\n# GRADIO INTERFACE FOR SQL GENERATION\n# =============================================================================\n\nimport gradio as gr\nimport torch\n\n# Install gradio first if not already installed\n!pip install gradio\n\ndef generate_sql_query(schema, question, model_choice):\n    \"\"\"Generate SQL using the selected fine-tuned model\"\"\"\n    \n    # Format input using the better prompting style\n    input_text = f\"\"\"Convert this natural language question to SQL using the given database schema.\n\nDatabase Schema:\n{schema}\n\nQuestion: {question}\n\nPlease generate a SQL query with explanation:\"\"\"\n    \n    try:\n        # Select model and tokenizer based on choice\n        if model_choice == \"CodeT5-Small (Fine-tuned)\":\n            model = codet5_model\n            tokenizer = codet5_tokenizer\n        else:  # FLAN-T5-Small (Fine-tuned)\n            model = t5_model  # This should be your FLAN-T5 model\n            tokenizer = t5_tokenizer\n        \n        # Tokenize input\n        inputs = tokenizer(\n            input_text,\n            return_tensors=\"pt\",\n            max_length=512,\n            truncation=True\n        ).to(device)\n        \n        # Generate prediction\n        with torch.no_grad():\n            outputs = model.generate(\n                **inputs,\n                max_length=256,\n                num_beams=3,\n                early_stopping=True,\n                do_sample=False,\n                pad_token_id=tokenizer.pad_token_id,\n                temperature=0.7\n            )\n        \n        # Decode prediction\n        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        return prediction\n        \n    except Exception as e:\n        return f\"Error generating SQL: {str(e)}\"\n\ndef create_sql_interface():\n    \"\"\"Create the Gradio interface\"\"\"\n    \n    # Custom CSS for better styling\n    css = \"\"\"\n    .gradio-container {\n        max-width: 1200px !important;\n    }\n    .output-text {\n        font-family: 'Courier New', monospace;\n        background-color: #f8f9fa;\n        padding: 10px;\n        border-radius: 5px;\n        border: 1px solid #dee2e6;\n    }\n    \"\"\"\n    \n    with gr.Blocks(css=css, title=\"Text-to-SQL Generator\", theme=gr.themes.Soft()) as demo:\n        \n        # Header\n        gr.Markdown(\"\"\"\n        # 🚀 Text-to-SQL Generator\n        ### Convert natural language questions to SQL queries using fine-tuned models\n        \n        **Models Available:**\n        - **CodeT5-Small**: Pre-trained on code, optimized for SQL generation\n        - **FLAN-T5-Small**: Instruction-tuned general language model\n        \"\"\")\n        \n        with gr.Row():\n            with gr.Column(scale=1):\n                # Input Section\n                gr.Markdown(\"## 📝 Input\")\n                \n                schema_input = gr.Textbox(\n                    label=\"Database Schema\",\n                    placeholder=\"CREATE TABLE employees (id INT, name VARCHAR(100), department VARCHAR(50), salary DECIMAL(10,2));\\nCREATE TABLE projects (id INT, name VARCHAR(100), budget DECIMAL(12,2));\",\n                    lines=8,\n                    value=\"\"\"CREATE TABLE employees (emp_id INT, name VARCHAR(100), department VARCHAR(50), salary DECIMAL(10,2));\nCREATE TABLE projects (project_id INT, project_name VARCHAR(100), budget DECIMAL(12,2));\"\"\",\n                    info=\"Enter your database schema with CREATE TABLE statements\"\n                )\n                \n                question_input = gr.Textbox(\n                    label=\"Natural Language Question\",\n                    placeholder=\"Find all employees with salary greater than 50000\",\n                    lines=3,\n                    value=\"Find all employees in the Engineering department\",\n                    info=\"Enter your question in plain English\"\n                )\n                \n                model_choice = gr.Radio(\n                    choices=[\"CodeT5-Small (Fine-tuned)\", \"FLAN-T5-Small (Fine-tuned)\"],\n                    label=\"Select Model\",\n                    value=\"CodeT5-Small (Fine-tuned)\",\n                    info=\"Choose which fine-tuned model to use\"\n                )\n                \n                generate_btn = gr.Button(\"🚀 Generate SQL\", variant=\"primary\", size=\"lg\")\n                \n                # Model Performance Info\n                gr.Markdown(\"\"\"\n                **Model Performance Summary:**\n                - **CodeT5**: Combined Score 0.658, 10% Exact Match\n                - **FLAN-T5**: Combined Score 0.546, 0% Exact Match\n                \"\"\")\n            \n            with gr.Column(scale=1):\n                # Output Section\n                gr.Markdown(\"## 🎯 Generated SQL\")\n                \n                output = gr.Textbox(\n                    label=\"SQL Query + Explanation\",\n                    lines=15,\n                    max_lines=25,\n                    elem_classes=[\"output-text\"],\n                    show_copy_button=True,\n                    info=\"Generated SQL query with explanation\"\n                )\n                \n                # Quick Analysis\n                analysis_output = gr.Textbox(\n                    label=\"Quick Analysis\",\n                    lines=3,\n                    visible=False,  # Can be made visible for advanced features\n                    info=\"Automatic analysis of the generated SQL\"\n                )\n        \n        # Example Queries Section\n        gr.Markdown(\"## 📚 Example Queries\")\n        \n        examples = gr.Examples(\n            examples=[\n                [\n                    \"\"\"CREATE TABLE customers (customer_id INT, name VARCHAR(100), city VARCHAR(50));\nCREATE TABLE orders (order_id INT, customer_id INT, amount DECIMAL(10,2), order_date DATE);\"\"\",\n                    \"Show customer names and their total order amounts\",\n                    \"CodeT5-Small (Fine-tuned)\"\n                ],\n                [\n                    \"\"\"CREATE TABLE employees (emp_id INT, name VARCHAR(100), department VARCHAR(50), salary DECIMAL(10,2));\"\"\",\n                    \"What is the average salary by department?\",\n                    \"CodeT5-Small (Fine-tuned)\"\n                ],\n                [\n                    \"\"\"CREATE TABLE products (product_id INT, name VARCHAR(100), category VARCHAR(50), price DECIMAL(10,2));\nCREATE TABLE sales (sale_id INT, product_id INT, quantity INT, sale_date DATE);\"\"\",\n                    \"Find the top 5 selling products by total quantity sold\",\n                    \"CodeT5-Small (Fine-tuned)\"\n                ],\n                [\n                    \"\"\"CREATE TABLE students (student_id INT, name VARCHAR(100), major VARCHAR(50));\nCREATE TABLE courses (course_id INT, course_name VARCHAR(100), credits INT);\nCREATE TABLE enrollments (student_id INT, course_id INT, grade VARCHAR(2));\"\"\",\n                    \"List all students majoring in Computer Science with their enrolled courses\",\n                    \"FLAN-T5-Small (Fine-tuned)\"\n                ]\n            ],\n            inputs=[schema_input, question_input, model_choice],\n            label=\"Try these examples:\"\n        )\n        \n        # Instructions\n        gr.Markdown(\"\"\"\n        ## 📋 Instructions\n        1. **Enter your database schema** in the first text box (use CREATE TABLE statements)\n        2. **Ask your question** in natural language\n        3. **Select a model** (CodeT5 generally performs better for SQL tasks)  \n        4. **Click Generate SQL** to get your query\n        5. **Copy the result** using the copy button in the output box\n        \n        ## ⚠️ Important Notes\n        - Models work best with **clear, specific questions**\n        - **CodeT5** generally produces more accurate SQL than FLAN-T5\n        - Results may vary for **complex multi-table queries**\n        - Always **validate generated SQL** before using in production\n        \"\"\")\n        \n        # Connect the generate button to the function\n        generate_btn.click(\n            fn=generate_sql_query,\n            inputs=[schema_input, question_input, model_choice],\n            outputs=output,\n            api_name=\"generate_sql\"\n        )\n    \n    return demo\n\n# Launch the interface\nprint(\"🚀 Creating SQL Generation Interface...\")\nprint(\"📊 Make sure your models are loaded (codet5_model, t5_model, etc.)\")\n\n# Create and launch the demo\ndemo = create_sql_interface()\ndemo.launch(\n    share=True,          # Creates public link\n    debug=True,          # Shows errors in console\n    server_name=\"0.0.0.0\",  # Allows external access\n    server_port=7860,    # Default Gradio port\n    show_error=True      # Shows errors in interface\n)\n\nprint(\"✅ Interface launched! Check the output above for the public URL.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T21:38:39.521808Z","iopub.execute_input":"2025-07-02T21:38:39.522571Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.35.0)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\nRequirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.14)\nRequirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\nRequirement already satisfied: gradio-client==1.10.4 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.4)\nRequirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\nRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.1)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\nRequirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.3)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\nRequirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\nRequirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.1)\nRequirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\nRequirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\nRequirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\nRequirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\nRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\nRequirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.4->gradio) (2025.3.2)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.4->gradio) (15.0.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.0->gradio) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n🚀 Creating SQL Generation Interface...\n📊 Make sure your models are loaded (codet5_model, t5_model, etc.)\n* Running on local URL:  http://0.0.0.0:7860\n* Running on public URL: https://d3766dd33907c53ba6.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://d3766dd33907c53ba6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T21:34:59.801196Z","iopub.status.idle":"2025-07-02T21:34:59.801443Z","shell.execute_reply.started":"2025-07-02T21:34:59.801322Z","shell.execute_reply":"2025-07-02T21:34:59.801336Z"}},"outputs":[],"execution_count":null}]}